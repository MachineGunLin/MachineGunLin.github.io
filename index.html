<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Hadoop学习笔记/7. Hadoop MapReduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20Hadoop%20MapReduce/" class="article-date">
  <time datetime="2020-06-19T05:50:36.545Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20Hadoop%20MapReduce/">Hadoop学习笔记/7. Hadoop MapReduce</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="7-Hadoop-MapReduce"><a href="#7-Hadoop-MapReduce" class="headerlink" title="7. Hadoop MapReduce"></a>7. Hadoop MapReduce</h1><p>MapReduce是一个可以在普通硬件的大集群上编写应用程序以并行、可靠的方式处理海量数据的框架。</p>
<h4 id="MapReduce是什么？"><a href="#MapReduce是什么？" class="headerlink" title="MapReduce是什么？"></a>MapReduce是什么？</h4><p>MapReduce是一种处理技术和程序模型的基于Java的分布式计算框架。</p>
<p>MapReduce算法包含了两项重要任务，即Map和Reduce。</p>
<p>Map采用了一组数据并将其转换成另一组数据，其中各个元件被分解成元祖（键/值对）。其次，减少任务，这需要从Map作为输入并组合那些数据元组成的一组小的元祖输出。</p>
<p>在Map作业之后执行reduce任务。</p>
<p>MapReduce的主要优点是，它很容易在多个计算节点处理大规模数据。下面的MapReduce模型中数据处理的原语被称为映射器和减速器。分解数据处理应用到映射器和减速器没什么大不了的，但要编写MapReduce形式的应用，扩展应用程序运行在几百，几千甚至几万集群中而仅仅通过一个配置的更改这种简单的可扩展性才是吸引众多程序员使用MR模型的原因。</p>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>通常MapReduce范例是基于发送数据的计算机的位置。</p>
<p>MapReduce计划分三个阶段执行，即映射阶段(map), shuffle阶段，减少阶段(reduce)。</p>
<ul>
<li>映射阶段：映射或映射器的工作是处理输入数据。一般输入数据是文件或目录的形式，并且被存储在Hadoop的文件系统（HDFS）。输入文件被传递到有限的映射器，映射器处理该数据，并创建数据的若干小块。</li>
<li>减少阶段：这个阶段是Shuffle阶段和Reduce阶段的组合。减速器的工作是处理来自映射器中的数据。处理之后，它产生一组新的输出，存储在HDFS。</li>
</ul>
<p>在一个MapReduce工作中，Hadoop发送Map和Reduce任务到集群的相应服务器。</p>
<p>框架管理数据传递，例如发出任务的所有节点之间的集群周围的详细信息，验证任务完成和复制数据。</p>
<p>大部分的计算发生在本地磁盘上，可以减少网络通信量。</p>
<p>给定任务完成后，将收集集群并减少数据，以形成一个合适的结果，并且将其发送回Hadoop服务器。</p>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615153527.png" alt="image-20200615141043783"></p>
<h4 id="输入和输出（Java透视图）"><a href="#输入和输出（Java透视图）" class="headerlink" title="输入和输出（Java透视图）"></a>输入和输出（Java透视图）</h4><p>MapReduce框架上对&lt;key, value&gt;对进行操作，也就是说框架视图中输入需要一组&lt;key, value&lt;对，并产生一组&lt;key, value&gt;对作为作业的输出。</p>
<p>需要实现接口。键类必须实现可写，可比（较）接口，以方便框架排序。</p>
<p>MapReduce工作的输入和输出类型：</p>
<p>（输入）&lt;k1, v1&gt; -&gt; 映射 -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt;（输出）</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">输入</th>
<th align="center">输出</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Map</td>
<td align="center">&lt;k1, v1&gt;</td>
<td align="center">list(&lt;k2, v2&gt;)</td>
</tr>
<tr>
<td align="center">Reduce</td>
<td align="center">&lt;k2, list(v2)&gt;</td>
<td align="center">list(&lt;k3, v3&gt;)</td>
</tr>
</tbody></table>
<h4 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h4><ul>
<li>PayLoad：应用程序实现映射和减少功能，形成工作的核心。</li>
<li>Mapper：映射器的输入键/值对映射到一组中间键/值对。</li>
<li>NameNode：节点管理Hadoop分布式文件系统（HDFS）。</li>
<li>DataNode：在任何处理发生之前呈现节点数据。</li>
<li>MasterNode：节点所在JobTracker运行并接受来自客户端作业请求。</li>
<li>SlaveNode：节点所在Map和Reduce程序运行在slave节点。</li>
<li>JobTracker：调度作业并跟踪作业分配给任务跟踪器。</li>
<li>Task Tracker：跟踪任务和报告状态的JobTracker。</li>
<li>Job：程序在整个数据集映射和减速的执行。</li>
<li>Task：一个映射程序的执行或对数据的一个片段的减速器。</li>
<li>Task Attempt：一种特定实例在SlaveNode执行任务的尝试。</li>
</ul>
<h4 id="重要命令"><a href="#重要命令" class="headerlink" title="重要命令"></a>重要命令</h4><p>所有的Hadoop命令都是由$HADOOP_HOME/bin/hadoop命令调用。</p>
<p>Usage: hadoop [–config confdir] COMMAND</p>
<p>下面列出了可用的选项以及说明。</p>
<table>
<thead>
<tr>
<th align="center">操作</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">namenode -format</td>
<td align="center">格式化DFS文件系统。</td>
</tr>
<tr>
<td align="center">secondarynamenode</td>
<td align="center">运行DFS二次名称文件。</td>
</tr>
<tr>
<td align="center">namenode</td>
<td align="center">运行DFS名称节点。</td>
</tr>
<tr>
<td align="center">datanode</td>
<td align="center">运行DFS的Datanode。</td>
</tr>
<tr>
<td align="center">dfsadmin</td>
<td align="center">运行DFS管理客户端。</td>
</tr>
<tr>
<td align="center">mradmin</td>
<td align="center">运行映射，减少管理客户端。</td>
</tr>
<tr>
<td align="center">fsck</td>
<td align="center">运行DFS文件系统检查工具。</td>
</tr>
<tr>
<td align="center">fs</td>
<td align="center">运行一个通用的文件系统的用户客户端。</td>
</tr>
<tr>
<td align="center">balancer</td>
<td align="center">运行集群平衡工具。</td>
</tr>
<tr>
<td align="center">oiv</td>
<td align="center">适用于离线Fslmage查看器的fsimage。</td>
</tr>
<tr>
<td align="center">fetchdt</td>
<td align="center">从NameNode获取团令牌。</td>
</tr>
<tr>
<td align="center">jobtracker</td>
<td align="center">运行MapReduce工作跟踪节点。</td>
</tr>
<tr>
<td align="center">pipes</td>
<td align="center">运行管道的工作。</td>
</tr>
<tr>
<td align="center">tasktracker</td>
<td align="center">运行MapReduce任务跟踪节点。</td>
</tr>
<tr>
<td align="center">historyserver</td>
<td align="center">运行作业历史记录服务器作为一个独立的守护进程。</td>
</tr>
<tr>
<td align="center">job</td>
<td align="center">操纵MapReduce工作。</td>
</tr>
<tr>
<td align="center">queue</td>
<td align="center">获取有关作业队列信息。</td>
</tr>
<tr>
<td align="center">version</td>
<td align="center">打印版本。</td>
</tr>
<tr>
<td align="center">jar <jar></td>
<td align="center">运行一个jar文件。</td>
</tr>
<tr>
<td align="center">distcp <srcurl> <desturl></td>
<td align="center">递归复制文件或目录。</td>
</tr>
<tr>
<td align="center">archive -archiveName NAME -p</td>
<td align="center">创建一个Hadoop的归档。</td>
</tr>
<tr>
<td align="center">classpath</td>
<td align="center">打印需要得到Hadoop jar和所需要的库的类路径。</td>
</tr>
<tr>
<td align="center">daemonlog</td>
<td align="center">为每个守护进程获取/设置日志级别。</td>
</tr>
</tbody></table>
<h4 id="如何与MapReduce工作互动"><a href="#如何与MapReduce工作互动" class="headerlink" title="如何与MapReduce工作互动"></a>如何与MapReduce工作互动</h4><p>Usage： hadoop job [GENERIC_OPTIONS]</p>
<p>一下是在一个Hadoop的作业的可用通用选项。</p>
<table>
<thead>
<tr>
<th align="center">GENERIC_OPTIONS</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-submit <job-file></td>
<td align="center">提交作业。</td>
</tr>
<tr>
<td align="center">status <job-id></td>
<td align="center">打印映射，并减少完成的百分比以及所有的工作的计数器。</td>
</tr>
<tr>
<td align="center">counter <job-id>  <group-name> <countername></td>
<td align="center">打印的计数器值。</td>
</tr>
<tr>
<td align="center">-events <job-id> &lt;fromevent-#&gt; &lt;#-of-events&gt;</td>
<td align="center">打印接收到JobTracker为给定范围内的事件的详细信息。</td>
</tr>
<tr>
<td align="center">-history [all] <jobOutputDir></td>
<td align="center">打印作业的详细信息，作业未能终止时提供详细的信息。有关作业的更多详细信息，如每个成功的任务，可以尝试通过制定[all]选项查看。</td>
</tr>
<tr>
<td align="center">-list[all]</td>
<td align="center">显示所有作业。-list只显示尚未完成的作业。</td>
</tr>
<tr>
<td align="center">-kill-task <task-id></td>
<td align="center">终止任务。终止任务不计入失败的尝试。</td>
</tr>
<tr>
<td align="center">-fail-task <task-id></td>
<td align="center">失败的任务。</td>
</tr>
<tr>
<td align="center">set-priority <job-id> <priority></td>
<td align="center">更改作业的优先级。允许设置的优先级有：VERY_HIGH, HIGH, NORMAL, LOW, VERY_LOW</td>
</tr>
</tbody></table>
<h5 id="查看作业的状态"><a href="#查看作业的状态" class="headerlink" title="查看作业的状态"></a>查看作业的状态</h5><blockquote>
<p>$ $HADOOP_HOME/bin/hadoop job -status <job-id></p>
<p>$ $HADOOP_HOME/bin/hadoop job -status job_20200615666_0001</p>
</blockquote>
<h5 id="在output-dir查看作业历史"><a href="#在output-dir查看作业历史" class="headerlink" title="在output-dir查看作业历史"></a>在output-dir查看作业历史</h5><blockquote>
<p>$ $HADOOP_HOME/bin/hadoop job -history <dir-name></p>
<p>$ $HADOOP_HOME/bin/hadoop job -history /user/expert/output</p>
</blockquote>
<h5 id="终止任务"><a href="#终止任务" class="headerlink" title="终止任务"></a>终止任务</h5><blockquote>
<p>$ $HADOOP_HOME/bin/hadoop job -kill <job-id></p>
<p>$ $HADOOP_HOME/bin/hadoop job -kill job_20200615666_0001</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20Hadoop%20MapReduce/" data-id="ckblsod4r0006m4tqftcfgixo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/6. Hadoop命令参考" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.%20Hadoop%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/" class="article-date">
  <time datetime="2020-06-19T05:50:36.540Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.%20Hadoop%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/">Hadoop学习笔记/6. Hadoop命令参考</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="6-Hadoop命令参考"><a href="#6-Hadoop命令参考" class="headerlink" title="6. Hadoop命令参考"></a>6. Hadoop命令参考</h1><p>在<code>$HADOOP_HOME/bin/hadoop fs</code>里有很多命令。</p>
<p>$HADOOP_HOME/bin/hadoop fs -help命令会显示一个简短的用法。</p>
<p>使用参数的一般方式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&quot;&lt;path&gt;&quot; 是文件或目录名称。</span><br><span class="line">&quot;&lt;path&gt;...&quot;是一个或者多个文件或目录名称。</span><br><span class="line">&quot;&lt;file&gt;&quot;指文件名字。</span><br><span class="line">&quot;&lt;src&gt;&quot;和&quot;&lt;dest&gt;&quot;是一个有向的操作的路径。</span><br><span class="line">&quot;&lt;localSrc&gt;&quot;和&quot;&lt;localDest&gt;&quot;是本地文件系统中一个有向操作的路径。</span><br></pre></td></tr></table></figure>

<p>所有其他文件和路径名是指HDFS内部的对象。</p>
<table>
<thead>
<tr>
<th>1.</th>
<th>ls <path> ：列出路径指定的目录中的内容，显示出名称，权限，拥有者，大小和修改日期等条目。</th>
</tr>
</thead>
<tbody><tr>
<td>2.</td>
<td><strong>lsr <path></strong>：行为类似于 -ls，但递归显示路径的所有子目录项。</td>
</tr>
<tr>
<td>3.</td>
<td><strong>du <path></strong>：显示磁盘使用率，以字节为单位，对所有的文件，这些文件匹配的路径，文件名报告使用完整HDFS协议前缀。</td>
</tr>
<tr>
<td>4.</td>
<td><strong>dus <path></strong>：类似-du，但打印路径中的所有文件/目录的磁盘使用情况的摘要。</td>
</tr>
<tr>
<td>5.</td>
<td><strong>mv <src> <dest></strong>：在HDFS的文件或目录里移动src到dest。</td>
</tr>
<tr>
<td>6.</td>
<td><strong>cp <src> <dest></strong>： 在HDFS里复制src中的文件或目录到dest。</td>
</tr>
<tr>
<td>7.</td>
<td><strong>rm <path></strong>： 删除文件或路径标识的空目录。</td>
</tr>
<tr>
<td>8.</td>
<td><strong>rmr <path></strong>：删除路径标识的文件或目录。递归删除所有子条目（例如，文件或路径的子目录）。</td>
</tr>
<tr>
<td>9.</td>
<td><strong>put <localSrc> <dest></strong>：从本地localSrc文件系统中的DFS标识文件或目录内复制到dest。</td>
</tr>
<tr>
<td>10.</td>
<td><strong>copyFromLocal <localSrc> <dest></strong>：等同于-put</td>
</tr>
<tr>
<td>11.</td>
<td><strong>moveFromLocal <localSrc>  <dest></strong>：从标识localSrc本地文件系统中的文件或目录中HDFS复制到dest，然后删除本地副本。</td>
</tr>
<tr>
<td>12.</td>
<td><strong>get [-crc] <src> <localDest></strong>：拷贝标识sr到localDest本地文件系统路径HDFS文件或目录。</td>
</tr>
<tr>
<td>13.</td>
<td><strong>getmerge <src> <localDest></strong>：检索匹配的路径的src HDFS中的所有文件，并将它们复制合并文件到标识localDest本地文件系统中。</td>
</tr>
<tr>
<td>14.</td>
<td><strong>cat <file-name></strong>：显示在标准输出文件名中的内容。</td>
</tr>
<tr>
<td>15.</td>
<td><strong>copyToLocal <src> <localDest></strong>：等同于-get</td>
</tr>
<tr>
<td>16.</td>
<td><strong>moveToLocal <src> <localDest></strong>：工作方式类似于-get，但删除HDFS复制成功。</td>
</tr>
<tr>
<td>17.</td>
<td><strong>mkdir <path></strong>：创建一个HDFS命名的目录路径。</td>
</tr>
<tr>
<td>18.</td>
<td><strong>setrep [-R] [-w] rep <path></strong>：设置标识路径代表文件的目标文件复制因子。（实际的复制因子会向着随着时间的推移目标移动）。</td>
</tr>
<tr>
<td>19.</td>
<td><strong>touchz <path></strong>：在路径上创建包含当前时间作为时间戳的文件。如果文件已经存在于路径上就失败，除非文件大小为0。</td>
</tr>
<tr>
<td>20.</td>
<td><strong>test -[ezd] <path></strong>：如果路径存在且长度为0则返回1，如果是1个目录或其他返回0。</td>
</tr>
<tr>
<td>21.</td>
<td><strong>stat [format] <path></strong>：打印有关的路径信息。格式是接收块文件大小(%b), 文件名(%n)， 块大小(%o), 复制(%r)和修改日期(%y, %Y)的字符串。</td>
</tr>
<tr>
<td>22.</td>
<td><strong>tail [-f] <file2name></strong>: 显示在标准输出文件的最后1KB。</td>
</tr>
<tr>
<td>23.</td>
<td><strong>chmod [-R] mode,mode,… <path> …</strong> : 变化符合路径标识的一个或多个对象关联的文件权限，-R是递归执行变更，模式是3为八进制模式（和Linux一样）。</td>
</tr>
<tr>
<td>24.</td>
<td><strong>chown [-R] [owner] [:[group]] <path>…</strong> ：设置所属组标识路径的文件或目录…如果指定-R就是设置组递归。</td>
</tr>
<tr>
<td>25.</td>
<td><strong>chgrp [-R] group <path>…</strong> ：设置所属组标识路径的文件或目录，-R设置组递归。</td>
</tr>
<tr>
<td>26.</td>
<td><strong>help <cmd-name></strong> ：返回使用上面列出的命令之一的信息。</td>
</tr>
</tbody></table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.%20Hadoop%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/" data-id="ckblsod4q0005m4tq3sl36g84" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/5. Hadoop HDFS操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%20Hadoop%20HDFS%E6%93%8D%E4%BD%9C/" class="article-date">
  <time datetime="2020-06-19T05:50:36.522Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%20Hadoop%20HDFS%E6%93%8D%E4%BD%9C/">Hadoop学习笔记/5. Hadoop HDFS操作</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="5-Hadoop-HDFS操作"><a href="#5-Hadoop-HDFS操作" class="headerlink" title="5. Hadoop HDFS操作"></a>5. Hadoop HDFS操作</h1><h4 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h4><p>首先，格式化配置HDFS文件系统，打开NameNode（HDFS服务器），然后执行以下命令：</p>
<blockquote>
<p>$ hadoop namenode -format</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615115851.png" alt="image-20200615115851890"></p>
<p>格式化HDFS后，启动分布式文件系统。以下命令将启动名称节点namenode和数据节点datanode的集群。<strong>注意要在hadoop目录下执行命令</strong>：</p>
<blockquote>
<p>$ sbin/start-dfs.sh</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615120149.png" alt="image-20200615120149031"></p>
<h4 id="HDFS的文件列表"><a href="#HDFS的文件列表" class="headerlink" title="HDFS的文件列表"></a>HDFS的文件列表</h4><p>加载服务器信息后，使用<code>ls</code>可以找出文件列表中的目录、文件状态。</p>
<p>下面是ls, 可以传递一个目录或文件名作为参数的语法：</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop fs - ls <args></p>
</blockquote>
<h4 id="将数据插入到HDFS"><a href="#将数据插入到HDFS" class="headerlink" title="将数据插入到HDFS"></a>将数据插入到HDFS</h4><p>假设在本地系统的file.txt文件中的数据应当保存在HDFS文件系统。</p>
<p>按照下面给出插入在Hadoop的文件系统所需要的文件的步骤。</p>
<p>第一步，必须创建一个输入目录。</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop fs -mkdir /user/input<img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615124556.png" alt="image-20200615124556221"></p>
</blockquote>
<p>第二步，传输并使用本地系统put命令，Hadoop文件系统中存储数据文件。</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop fs -put /root/file.txt /user/input</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615124756.png" alt="image-20200615124755971"></p>
<p>第三步，使用ls命令验证文件。</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop fs -ls /user/input</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615124904.png" alt="image-20200615124904781"></p>
<h4 id="从HDFS中检索数据"><a href="#从HDFS中检索数据" class="headerlink" title="从HDFS中检索数据"></a>从HDFS中检索数据</h4><p>假设在HDFS中文件名为file.txt。</p>
<p>检索从Hadoop文件系统的文件：</p>
<p>第一步，使用cat命令查看来自HDFS的数据</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop fs -cat /user/input/file.txt</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615125109.png" alt="image-20200615125109030"></p>
<p>第二步，从HDFS得到文件使用get命令到本地文件系统</p>
<blockquote>
<p>$ $HADOOP_HOME/bin/hadoop      fs    -get /user/input/     /root/hadoop_tp/</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615125641.png" alt="image-20200615125641497"></p>
<p>HDFS的文件get到了本地文件系统。</p>
<h4 id="关闭HDFS"><a href="#关闭HDFS" class="headerlink" title="关闭HDFS"></a>关闭HDFS</h4><blockquote>
<p>$ $HADOOP_HOME/sbin/stop-dfs.sh</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615134150.png" alt="image-20200615125824698"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%20Hadoop%20HDFS%E6%93%8D%E4%BD%9C/" data-id="ckblsod4p0004m4tqct0m93a3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/4. Hadoop HDFS" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.%20Hadoop%20HDFS/" class="article-date">
  <time datetime="2020-06-19T05:50:36.516Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.%20Hadoop%20HDFS/">Hadoop学习笔记/4. Hadoop HDFS</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="4-Hadoop-HDFS"><a href="#4-Hadoop-HDFS" class="headerlink" title="4. Hadoop HDFS"></a>4. Hadoop HDFS</h1><p>Hadoop文件系统使用分布式文件系统设计开发。不像其他的分布式系统，它运行在普通硬件。</p>
<p>HDFS是高度容错以及使用低成本的硬件设计的文件系统。</p>
<p>HDFS拥有超大型的数据量，并提供了更轻松的访问。为了存储这些庞大的数据，这些文件都存储在多台机器上。这些文件的存储是以冗余的方式来保护系统在发生故障时免受可能的数据丢失。HDFS也可以并行处理应用程序。</p>
<h4 id="HDFS的特点"><a href="#HDFS的特点" class="headerlink" title="HDFS的特点"></a>HDFS的特点</h4><ul>
<li>它适用于分布式存储和处理。</li>
<li>Hadoop提供的命令接口与HDFS进行交互。</li>
<li>名称节点（namenode）和数据节点（datanode）帮助用户通过内置的服务器轻松检查集群的状态。</li>
<li>流式访问文件系统数据。</li>
<li>HDFS提供了文件的权限和验证。</li>
</ul>
<h4 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h4><p>Hadoop文件系统的体系结构如图：</p>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615113835.png" alt="image-20200615113835324"></p>
<p>HDFS遵循主从架构，它具有以下元素：</p>
<h5 id="名称节点-Namenode"><a href="#名称节点-Namenode" class="headerlink" title="名称节点 - Namenode"></a>名称节点 - Namenode</h5><p>名称节点是包含GNU/Linux操作系统和软件名称节点的普通硬件。它是一个可以在商业硬件上运行的软件。</p>
<p>具有名称节点的系统作为主服务器。它执行以下任务：</p>
<ul>
<li>管理文件系统命名空间。</li>
<li>规范客户端对文件的访问。</li>
<li>它也执行文件系统操作。如重命名，关闭和打开文件和目录。</li>
</ul>
<h5 id="数据节点-Datanode"><a href="#数据节点-Datanode" class="headerlink" title="数据节点 - Datanode"></a>数据节点 - Datanode</h5><p>Datanode是具有GNU/Linux操作系统和软件Datanode的普通硬件。对于集群中的每个节点（普通硬件/系统），有一个数据节点。这些节点管理数据并存储在它们的系统。</p>
<ul>
<li>数据节点上的文件系统根据用户请求执行读写操作。</li>
<li>还可以根据名称节点的指令执行操作，如块的创建，删除和复制。</li>
</ul>
<h4 id="块"><a href="#块" class="headerlink" title="块"></a>块</h4><p>一般用户数据存储在HDFS文件系统。</p>
<p>在一个文件系统中的文件被划分为一个或多个段和/或存储在个人数据的节点。这些文件段被称为块。</p>
<p>也就是说数据的HDFS可以读取或写入的最小量被称为一个块。缺省的块大小为64MB，这可以按需根据HDFS配置来改变。</p>
<h4 id="HDFS的目标"><a href="#HDFS的目标" class="headerlink" title="HDFS的目标"></a>HDFS的目标</h4><ul>
<li>故障检测和恢复：由于HDFS包括大量的普通硬件，部件故障频繁。因此HDFS应该具有快速和自动的故障检测和恢复机制。</li>
<li>巨大的数据集：HDFS有数百个集群节点来管理其庞大的数据集的应用程序。</li>
<li>数据硬件：请求的任务当计算发生不久后可以高效的完成。HDFS涉及到巨大的数据集，它需要减少网络通信量，增加吞吐量。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.%20Hadoop%20HDFS/" data-id="ckblsod4o0003m4tq8yi709mp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/3. Hadoop是什么" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.%20Hadoop%E6%98%AF%E4%BB%80%E4%B9%88/" class="article-date">
  <time datetime="2020-06-19T05:50:36.512Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.%20Hadoop%E6%98%AF%E4%BB%80%E4%B9%88/">Hadoop学习笔记/3. Hadoop是什么</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="3-Hadoop是什么"><a href="#3-Hadoop是什么" class="headerlink" title="3. Hadoop是什么"></a>3. Hadoop是什么</h1><p>Hadoop是使用Java编写的、允许分布在集群、使用简单的编程模型的计算机处理大型数据集的Apache开源框架。</p>
<p>Hadoop框架应用了工程提供的跨计算机集群的分布式存储和计算的环境，是专为从单一服务器扩展到上千台服务器、让每个机器都可以提供本地计算和存储的框架。</p>
<h4 id="Hadoop的架构"><a href="#Hadoop的架构" class="headerlink" title="Hadoop的架构"></a>Hadoop的架构</h4><p>在其核心，Hadoop主要有两个层次，即：</p>
<ul>
<li>加工/计算层（MapReduce）</li>
<li>存储层（Hadoop分布式文件系统）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615110250.png" alt="image-20200615110250391"></p>
<h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><p>MapReduce是一种并行编程模型，用于编写普通硬件的设计，谷歌对大量数据的高效处理（多TB数据集）的分布式应用在大型集群（数千个节点）以及可靠的容错方式。</p>
<p>MapReduce程序可在Apache的开源框架Hadoop上运行。</p>
<h4 id="Hadoop分布式文件系统"><a href="#Hadoop分布式文件系统" class="headerlink" title="Hadoop分布式文件系统"></a>Hadoop分布式文件系统</h4><p>Hadoop分布式文件系统（HDFS）基于谷歌文件系统（GFS），并提供了一个设计在普通硬件上运行的分布式文件系统。它与现有的分布式文件系统有许多相似之处。它高度容错并设计成部署在低成本的硬件上。</p>
<p>HDFS提供了高吞吐量的应用数据访问，并适用于具有大数据集的应用程序。</p>
<p>除了上面提到的两个核心组件，Hadoop框架还包括以下两个模块：</p>
<ul>
<li>Hadoop通用工具(Common Utilities）：Java库和其他的Hadoop组件所需要的实用工具。</li>
<li>Hadoop YARN：这是作业调度和集群资源管理的框架。</li>
</ul>
<h4 id="Hadoop如何工作？"><a href="#Hadoop如何工作？" class="headerlink" title="Hadoop如何工作？"></a>Hadoop如何工作？</h4><p>建立重新配置、处理大规模数据的服务器是相当昂贵的。</p>
<p>作为替代，可以联系许多采用单CPU的普通电脑在一起，作为一个单一功能的分布式系统。</p>
<p>实际上，集群的机器可以并行地获取数据集，并提供一个高得多的吞吐量。此外，这样比一个高端服务器的价格更便宜，因此使用Hadoop跨集群在低成本上的机器上运行是一个不错的选择。</p>
<p>Hadoop运行整个计算机集群的代码。这个过程包括以下核心任务由Hadoop执行：</p>
<ul>
<li>数据最初分为目录和文件。文件分为64M和128M（最好用128M）统一大小块。</li>
<li>然后这些文件被分布在不同的集群节点，以便进一步处理。</li>
<li>HDFS在本地文件系统的顶端监督处理。</li>
<li>块复制处理硬件故障。</li>
<li>检查代码是否已成功执行。</li>
<li>执行发生映射之间，减少阶段的排序。</li>
<li>发送排序的数据到某一个计算机。</li>
<li>为每个作业编写调试日志。</li>
</ul>
<h4 id="Hadoop的优势"><a href="#Hadoop的优势" class="headerlink" title="Hadoop的优势"></a>Hadoop的优势</h4><ul>
<li>Hadoop框架允许用户快速编写和测试分布式系统。有效地在整个集群上自动分配数据和工作，充分利用CPU内核的基本并行度。</li>
<li>Hadoop不依赖硬件，提供容错和高可用性（fault tolerance and high availability, FTHA），Hadoop库本身已被设计在应用层，可以检测和处理故障。</li>
<li>服务器可以添加或从集群动态删除，Hadoop可继续不中断地运行。</li>
<li>Hadoop是开源的的，它基于Java并兼容所有的平台。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.%20Hadoop%E6%98%AF%E4%BB%80%E4%B9%88/" data-id="ckblsod4o0002m4tq9jxk7t71" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/2. Hadoop大数据解决方案" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.%20Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" class="article-date">
  <time datetime="2020-06-19T05:50:36.476Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.%20Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/">Hadoop学习笔记/2. Hadoop大数据解决方案</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="2-Hadoop大数据解决方案"><a href="#2-Hadoop大数据解决方案" class="headerlink" title="2. Hadoop大数据解决方案"></a>2. Hadoop大数据解决方案</h1><h4 id="传统的企业方法"><a href="#传统的企业方法" class="headerlink" title="传统的企业方法"></a>传统的企业方法</h4><p>在这种方法中，一个企业将有一个计算机存储和处理大数据。</p>
<p>对于存储而言，程序员会自己选择数据库厂商，如在Oracle, IBM等的帮助下完成，通过用户交互和使用应用程序进而获取并处理数据存储和分析。</p>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615105158.png" alt="image-20200615105158230"></p>
<h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><p>这种方式能完美地处理那些可以由标准的数据库服务器来存储、处理数据的服务器较少的数据。</p>
<p>但是当设计到大量的可伸缩数据，这是一个繁忙的业务，只能通过单一的数据库瓶颈来处理这些数据。</p>
<h4 id="谷歌的解决方案"><a href="#谷歌的解决方案" class="headerlink" title="谷歌的解决方案"></a>谷歌的解决方案</h4><p>谷歌使用一种称为MapReduce的算法解决了这个问题。这个算法将任务分成小份，并将它们分配到多台计算机，并且从这些机器收集结果并综合，形成了结果数据集。</p>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615105657.png" alt="image-20200615105657455"></p>
<h4 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h4><p>使用谷歌提供的解决方案，Doug Cutting和他的团队开发了一个开源项目叫做Hadoop。</p>
<p>Hadoop使用MapReduce算法运行。</p>
<p>Hadoop用于开发可以执行完整的统计分析大数据的应用程序。</p>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615105852.png" alt="image-20200615105852848"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.%20Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" data-id="ckblsod4n0001m4tq3xpyben3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop学习笔记/1. Hadoop简介" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%20Hadoop%E7%AE%80%E4%BB%8B/" class="article-date">
  <time datetime="2020-06-19T05:50:36.463Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%20Hadoop%E7%AE%80%E4%BB%8B/">Hadoop学习笔记/1. Hadoop简介</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-Hadoop简介"><a href="#1-Hadoop简介" class="headerlink" title="1. Hadoop简介"></a>1. Hadoop简介</h1><p>Hadoop是一个开源框架，它允许整个集群使用简单编程模型的计算机，在分布式环境存储并处理大数据。它的目的是从单一的服务器到上千台机器的扩展，每一台机器都可以提供本地计算和存储。</p>
<h4 id="什么是大数据？"><a href="#什么是大数据？" class="headerlink" title="什么是大数据？"></a>什么是大数据？</h4><p>大数据是不能用传统的计算机技术处理的大型数据集的集合。它不是一个单一的技术或工具，而是涉及的业务和技术的许多领域。</p>
<h4 id="大数据应用场景"><a href="#大数据应用场景" class="headerlink" title="大数据应用场景"></a>大数据应用场景</h4><p>大数据包括不同的设备和应用程序所产生的数据。应用场景包括：</p>
<ul>
<li>黑匣子数据：这是直升机、飞机、喷气机的一个组成部分，它捕获飞行机组的声音、麦克风和耳机的录音，以及飞机的性能信息。</li>
<li>社会化媒体数据：社交网络如Facebook和Twitter。</li>
<li>证券交易所数据：交易所数据保存有关的“买入”和“卖出”等信息。</li>
<li>电网数据：电网数据保持相对于基站所消耗的特定节点的信息。</li>
<li>交通运输数据：交通数据包括车辆的型号、容量、距离和可用性。</li>
<li>搜索引擎数据：搜索引擎获取大量来自不同数据库中的数据。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200615103132.png" alt="image-20200615103123677"></p>
<p>因此，大数据包括体积庞大、高流速和扩扩展的各种数据。</p>
<p>数据分为三种类型：</p>
<ul>
<li>结构化数据：关系数据。</li>
<li>半结构化数据：XML数据。</li>
<li>非结构化数据：Word, PDF, 文本，媒体日志。</li>
</ul>
<h4 id="大数据技术"><a href="#大数据技术" class="headerlink" title="大数据技术"></a>大数据技术</h4><p>大数据技术是为了提供更准确的分析，这可能影响更多的具体决策，可以提高运行效率、降低成本、减少业务风险。</p>
<p>为了利用大数据，需要管理和处理实时的结构化和非结构化的海量数据，还需要可以保护数据隐私和安全的基础设施。</p>
<p>主要研究两类技术：</p>
<h5 id="操作大数据"><a href="#操作大数据" class="headerlink" title="操作大数据"></a>操作大数据</h5><p>这些包括像MongoDB系统，提供业务实时的能力，主要是数据捕获和存储互动工作。</p>
<p>NoSQL大数据系统的设计充分利用了过去让大量的计算机以廉价高效运行的云计算架构的优势。这使得运营大数据工作负载更容易管理、更便宜、更快。</p>
<p>一些NoSQL系统可以提供深入了解基于使用最少的编码而无需数据科学家和额外的基础架构的实时数据模式。</p>
<h5 id="分析大数据"><a href="#分析大数据" class="headerlink" title="分析大数据"></a>分析大数据</h5><p>这些包括如大规模并行处理（MPP）数据库系统和MapReduce提供触及大部分或全部数据的分析能力的系统。</p>
<p>MapReduce在提供分析数据的基础上，可以按比例从单个服务器扩展到成千上万个高端和低端机。</p>
<p>这两类技术是互补的，并且经常一起部署。</p>
<h4 id="操作和分析系统"><a href="#操作和分析系统" class="headerlink" title="操作和分析系统"></a>操作和分析系统</h4><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">操作</th>
<th align="center">分析</th>
</tr>
</thead>
<tbody><tr>
<td align="center">等待时间</td>
<td align="center">1ms ~ 100ms</td>
<td align="center">1min ~ 100min</td>
</tr>
<tr>
<td align="center">并发</td>
<td align="center">1000 ～ 100000</td>
<td align="center">1 ～ 10</td>
</tr>
<tr>
<td align="center">访问模式</td>
<td align="center">写入和读取</td>
<td align="center">读取</td>
</tr>
<tr>
<td align="center">查询</td>
<td align="center">选择</td>
<td align="center">非选择性</td>
</tr>
<tr>
<td align="center">数据范围</td>
<td align="center">操作</td>
<td align="center">回溯</td>
</tr>
<tr>
<td align="center">最终用户</td>
<td align="center">顾客</td>
<td align="center">数据科学家</td>
</tr>
<tr>
<td align="center">技术</td>
<td align="center">NoSQL</td>
<td align="center">MapReduce、MPP数据库</td>
</tr>
</tbody></table>
<h4 id="大数据的挑战"><a href="#大数据的挑战" class="headerlink" title="大数据的挑战"></a>大数据的挑战</h4><p>大数据相关的主要挑战如下：</p>
<ul>
<li>采集数据</li>
<li>策展</li>
<li>存储</li>
<li>搜索</li>
<li>分享</li>
<li>传输</li>
<li>分析</li>
<li>展示</li>
</ul>
<p>为了应对上述挑战，企业通常需要企业级服务器的帮助。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.%20Hadoop%E7%AE%80%E4%BB%8B/" data-id="ckblsod4h0000m4tq7ochc5s7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Spark学习笔记/9. Spark Filter函数" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.%20Spark%20Filter%E5%87%BD%E6%95%B0/" class="article-date">
  <time datetime="2020-06-19T05:47:23.268Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.%20Spark%20Filter%E5%87%BD%E6%95%B0/">Spark学习笔记/9. Spark Filter函数</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="9-Spark-Filter函数"><a href="#9-Spark-Filter函数" class="headerlink" title="9. Spark Filter函数"></a>9. Spark Filter函数</h1><p>在Spark中，Filter函数返回一个新数据集，该数据集是通过选择函数返回<code>true</code>的源元素而形成的。因此它仅检索满足给定条件的元素。</p>
<h4 id="Filter函数示例"><a href="#Filter函数示例" class="headerlink" title="Filter函数示例"></a>Filter函数示例</h4><p>在此示例中，将过滤给定数据并检索<strong>除35之外的所有值</strong>。</p>
<p>在Scala模式下打开Spark:</p>
<blockquote>
<p>$ spark-shell</p>
</blockquote>
<p>使用并行化集合创建RDD：</p>
<blockquote>
<p>scala&gt; val data = sc.parallelize(List(10, 20, 35, 40))</p>
</blockquote>
<p>读取生成的结果：</p>
<blockquote>
<p>scala&gt; data.collect</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612092833226.png" alt="image-20200612092833226"></p>
<p>使用过滤器filter函数并传递执行所需的表达式:</p>
<blockquote>
<p>scala&gt; val filterfunc = data.filter(x =&gt; x != 35)</p>
</blockquote>
<p>读取生成的结果（理论上应该去掉集合中的35）：</p>
<blockquote>
<p>scala&gt; filterfunc.collect</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612093031124.png" alt="image-20200612093031124"></p>
<p>确实把集合中的元素35给过滤掉了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.%20Spark%20Filter%E5%87%BD%E6%95%B0/" data-id="ckblska73000llktqgi1a64fd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Spark学习笔记/8. Spark Map函数" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%20Spark%20Map%E5%87%BD%E6%95%B0/" class="article-date">
  <time datetime="2020-06-19T05:47:23.253Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%20Spark%20Map%E5%87%BD%E6%95%B0/">Spark学习笔记/8. Spark Map函数</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="8-Spark-Map函数"><a href="#8-Spark-Map函数" class="headerlink" title="8. Spark Map函数"></a>8. Spark Map函数</h1><p>在Spark中，Map通过函数传递源的每个元素，并形成新的分布式数据集。</p>
<h4 id="Map函数示例"><a href="#Map函数示例" class="headerlink" title="Map函数示例"></a>Map函数示例</h4><p>为每一个元素添加一个常量值。在Scala模式下打开Spark：</p>
<blockquote>
<p>$ spark-shell</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612091757.png" alt="image-20200612091716714"></p>
<p>使用并行化集合创建RDD：</p>
<blockquote>
<p>scala&gt; val data = sc.parallelize(List(10, 20, 30))</p>
</blockquote>
<p>读取生成的结果：</p>
<blockquote>
<p>scala&gt; data.collect</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612091941.png" alt="image-20200612091941156"></p>
<p>应用map函数并传递所需的表达式：</p>
<blockquote>
<p>scala: val mapfunc = data.map(x =&gt; x + 10)</p>
</blockquote>
<p>读取生成的结果：</p>
<blockquote>
<p>scala&gt; mapfunc.collect</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200612092122.png" alt="image-20200612092122547"></p>
<p>data集合中的每个元素的值都加了10.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.%20Spark%20Map%E5%87%BD%E6%95%B0/" data-id="ckblska71000ilktq4wfm5nbc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Spark学习笔记/7. RDD共享变量" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20RDD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/" class="article-date">
  <time datetime="2020-06-19T05:47:23.237Z" itemprop="datePublished">2020-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20RDD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/">Spark学习笔记/7. RDD共享变量</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="7-RDD共享变量"><a href="#7-RDD共享变量" class="headerlink" title="7. RDD共享变量"></a>7. RDD共享变量</h1><p>在Spark中，当任何函数传递给转换操作时，它将会在远程集群节点上运行。它适用于函数中使用的所有变量的不同副本。这些变量将复制到每台计算机，并且远程计算机上的变量更新不会恢复到驱动程序。</p>
<h4 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h4><p>广播变量支持在每台机器上缓存只读变量，而不是提供任务的副本。Spark使用传播算法来分发广播变量以降低通信成本。</p>
<p>Spark动作的执行经过几个阶段，由分布式<code>shuffle</code>操作分开。Spark自动广播每个阶段中任务所需的公共数据。以这种方式广播的数据以序列化形式缓存并在运行每个任务之前反序列化。</p>
<p>要创建广播变量（比如<code>v</code>），请调用<code>SparkContext.broadcast(v)</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val v &#x3D; sc.broadcast(Array(1, 2, 3))</span><br><span class="line">scala&gt; v.value</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200611191053.png" alt="image-20200611191053722"></p>
<h4 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h4><p>累加器适用于执行关联和交换操作（例如计数器或总和）的变量。</p>
<p>Spark为数字类型的累加器提供支持，还可以添加对新类型的支持。</p>
<p>要创建数字累加器，请调用<code>SparkContext.longAccumulator()</code>或<code>SparkContext.doubleAccumulator()</code>以累积<code>long</code>或<code>Double</code>类型的值。</p>
<p>示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a &#x3D; sc.longAccumulator(&quot;Accumulator&quot;)</span><br><span class="line">scala&gt; sc.parallelize(Array(2, 5)).foreach(x&#x3D;&gt;a.add(x))</span><br><span class="line">scala&gt; a.value</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/MachineGunLin/markdown_pics/master/img/20200611190854.png" alt="image-20200611190853900"></p>
<p>累加数组元素（2 + 5 = 7）</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20RDD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/" data-id="ckblska73000klktq2nx35hzj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.%20Hadoop%20MapReduce/">Hadoop学习笔记/7. Hadoop MapReduce</a>
          </li>
        
          <li>
            <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.%20Hadoop%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/">Hadoop学习笔记/6. Hadoop命令参考</a>
          </li>
        
          <li>
            <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.%20Hadoop%20HDFS%E6%93%8D%E4%BD%9C/">Hadoop学习笔记/5. Hadoop HDFS操作</a>
          </li>
        
          <li>
            <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.%20Hadoop%20HDFS/">Hadoop学习笔记/4. Hadoop HDFS</a>
          </li>
        
          <li>
            <a href="/2020/06/19/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.%20Hadoop%E6%98%AF%E4%BB%80%E4%B9%88/">Hadoop学习笔记/3. Hadoop是什么</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>